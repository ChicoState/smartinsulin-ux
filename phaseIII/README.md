# Phase III: Prototypes and User Testing

## Introduction

In Phase III, our team conducted a user study to test the usability of our SmartInsulin mobile application prototype. The prototype was refined based on insights from the earlier phases, and this final evaluation focused on how well users could navigate its core features. We observed how participants interacted with the prototype in simulated real-world scenarios, with the goal of identifying areas for improvement before finalizing the design.

## Methods

To evaluate the usability of our SmartInsulin prototype, we conducted a structured user study simulating realistic scenarios for individuals managing Type 2 diabetes. The purpose of the study was to identify usability strengths and pain points across key features of the interface, interactions, and flows, such as setup, data sharing, note logging, trend analysis, and caregiver support.

This was a formative usability study, designed to inform design decisions while the prototype is still evolving. We used the think-aloud protocol, where participants verbalized their thoughts, reactions, and confusion while performing tasks. This method allowed us to gain insight into user decision-making, expectations, and perceptions of ease-of-use.

The study included two parts:

1. Preliminary questions to understand user background and expectations
2. Six task-based scenarios that reflect real-world use cases of the SmartInsulin app

We recorded participants’ behavior, task success, and post-task feedback, including:
- Whether they completed the task
- A self-reported difficulty score (1 = Very Difficult, 5 = Very Easy)
- Open-ended responses explaining their experience

**Preliminary Questions**
We began by asking participants about their familiarity with diabetes management. Based on their answer to the initial question, we followed two separate paths:

> **Q: Are you currently managing diabetes for yourself or someone else?**

If **NO**:
Participants who did not manage diabetes were asked:

> Are you currently managing diabetes for yourself or someone else?

> If not, how familiar are you with how Type 2 diabetes is typically managed?

> Have you ever seen or heard about devices or apps that help people manage their diabetes?

> What challenges do you think people with Type 2 diabetes face when managing their blood sugar levels?

> Have you had a family member, friend, or colleague who uses an insulin pump or app?

> What features would you want in a smart insulin system (e.g., tracking, dosage suggestions, alerts)?

> When thinking about health apps, what makes one feel trustworthy and easy to use?


If **YES**:
Participants who did manage diabetes (for themselves or others) were asked:

> What methods or tools do you use to track glucose levels or insulin? e.g., apps, paper logs, insulin pumps, etc.

> What challenges or frustrations do you face when managing your insulin or glucose levels?

> Do you currently use any mobile apps or digital tools to help with diabetes management? Or have you in the past? If YES, what have you liked or disliked about those tools? If NO, why not?

> What features would you find most helpful in a smart insulin system? e.g., automatic tracking, dosage suggestions, alerts, etc.

Then, we gave people several tasks to do using the wireframe prototype. We wrote down how they moved through the app and what they said as they were thinking aloud.

**Task 1: App Setup and Pump Pairing**

Participants were asked to imagine they had just received a smart insulin pump and were setting up the app for the first time. This included pairing the device, entering personal details, and configuring delivery preferences.

After they finished, we asked:

> Task completed successfully: ☐ Yes ☐ No

> On a scale from 1 to 5, how would you rate completing this task, where 1 = Very Difficult, 5 = Very Easy?  Why did you give that rating?


This task aimed to test the onboarding experience, clarity of instructions, and overall ease of initial configuration.

**Task 2: Exporting Blood Sugar Reports**

Participants were required to use the app's export feature to generate a report of blood sugar levels from the past weeks and save it as a PDF to share with their healthcare provider.

After they finished, we asked: 

> Task completed successfully: ☐ Yes ☐ No

>On a scale from 1 to 5, how would you rate completing this task, where 1 = Very Difficult, 5 = Very Easy?  Why did you give that rating?


This task aims to evaluate the discoverability and usability of the export/share feature, as well as trust in the report’s formatting.

**Task 3: Logging an Unusual Reading**

Participants were asked to record a note explaining an abnormal blood sugar reading (e.g., after a large meal or stress).

After they finished, we asked: 

> Task completed successfully: ☐ Yes ☐ No

> On a scale from 1 to 5, how would you rate completing this task, where 1 = Very Difficult, 5 = Very Easy?  Why did you give that rating?

This task aims to assess flexibility in logging contextual information and the intuitiveness of manual input.

**Task 4: Using the Chat Assistant**

Participants used the in-app chat to ask a dietary question: For example, "How many carbs are typically in a medium-sized banana?"

After they finished, we asked: 

> Task completed successfully: ☐ Yes ☐ No

> On a scale from 1 to 5, how would you rate completing this task, where 1 = Very Difficult, 5 = Very Easy?  Why did you give that rating?

This task aims to examine the usability and usefulness of AI-driven interaction, as well as trust in health-related answers.

**Task 5: Viewing Trends and Summaries**

Participants reviewed recent glucose and insulin trends using the app’s analytics dashboard.

After they finished, we asked-

> Task completed successfully: ☐ Yes ☐ No

> On a scale from 1 to 5, how would you rate completing this task, where 1 = Very Difficult, 5 = Very Easy?  Why did you give that rating?

This task aims to evaluate the readability of data visualizations, the layout of insights, and user comprehension of trends.

**Task 6: Caregiver Monitoring**

Participants imagined monitoring a loved one’s diabetes data and were asked to review recent trends, alerts, and insulin history.

After they finished, we asked- 

> Task completed successfully: ☐ Yes ☐ No

>On a scale from 1 to 5, how would you rate completing this task, where 1 = Very Difficult, 5 = Very Easy?  Why did you give that rating?

This task aims to test multi-user support, caregiver access, and clarity of information in a remote monitoring context.

**Post-Session Debrief**

At the end of the session, participants were asked to reflect on their experience:

> What did you like most about the interface or experience?

> What did you find confusing or difficult?

> Were there any features you expected but didn’t find?

> How confident would you feel using this app for yourself or someone else?

> What would you change to make it better?

> Would you be interested in future testing or feedback sessions?

These questions helped us identify unmet expectations, areas for improvement, and overall user sentiment.



## Findings

!!! For each research method, detail each of the findings to clarify new discoveries of users' needs !!!

## Conclusions

!!! Discoveries derived from the methods and their findings. Interpret how the findings translate into new insights into UX design recommendations. Describe those recommendations and how they should shape future work. In this section, include the new design recommendations based on the latest user insights. !!!

## Caveats

!!! Considerations and/or limitations to the methods you chose and the findings/conclusions drawn from them. In other words, give warnings if there are limitations to your research such as not being able to find enough users of a particular demographic, the methods not being able to expose certain information, assumptions you made, etc. !!!
